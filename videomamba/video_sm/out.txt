Not using distributed mode
Namespace(batch_size=128, epochs=80, update_freq=1, save_ckpt_freq=10, model='videomamba_middle', tubelet_size=1, orig_t_size=8, input_size=224, use_learnable_pos_emb=False, fc_drop_rate=0.0, drop=0.0, attn_drop_rate=0.0, drop_path=0.4, disable_eval_during_finetuning=False, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=[0.9, 0.999], clip_grad=None, momentum=0.9, weight_decay=0.05, weight_decay_end=None, lr=0.001, layer_decay=0.8, warmup_lr=1e-06, min_lr=1e-06, warmup_epochs=5, warmup_steps=-1, color_jitter=0.4, num_sample=1, aa='rand-m7-n4-mstd0.5-inc1', smoothing=0.0, train_interpolation='bicubic', crop_pct=None, short_side_size=224, test_num_segment=4, test_num_crop=3, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='videomamba_m16_k400_mask_ft_f16_res224.pth', delete_head=False, model_key='model|module', model_prefix='', init_scale=0.001, use_checkpoint=True, checkpoint_num=0, use_mean_pooling=True, prefix='./', split=',', filename_tmpl='img_{:05}.jpg', data_path='data', eval_data_path=None, nb_classes=28, imagenet_default_mean_and_std=True, use_decord=True, num_segments=1, num_frames=32, sampling_rate=4, trimmed=60, time_stride=16, data_set='Kinetics_sparse', output_dir='exp_7/videomamba_middle_mask_f322_skip4_res224', log_dir='exp_7/videomamba_middle_mask_f322_skip4_res224', device='cuda', seed=0, resume='', auto_resume=True, save_ckpt=True, start_epoch=0, test_best=True, eval=True, dist_eval=True, num_workers=1, pin_mem=True, no_amp=False, world_size=1, local_rank=-1, dist_on_itp=False, dist_url='env://', enable_deepspeed=False, bf16=False, distributed=False)
Use Dataset: Kinetics_sparse
Number of the class = 28
Use Dataset: Kinetics_sparse
Number of the class = 28
Use Dataset: Kinetics_sparse
Number of the class = 28
Sampler_train = <torch.utils.data.distributed.DistributedSampler object at 0x7f7553f7fcd0>
Mixup is activated!
Use checkpoint: True
Checkpoint number: 0
Patch size = (16, 16)
Load ckpt from videomamba_m16_k400_mask_ft_f16_res224.pth
Temporal interpolate from 8 to 32
size mismatch for head.weight: copying a param with shape torch.Size([400, 576]) from checkpoint, the shape in current model is torch.Size([28, 576]).
size mismatch for head.bias: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([28]).
Model = VisionMamba(
  (patch_embed): PatchEmbed(
    (proj): Conv3d(3, 576, kernel_size=(1, 16, 16), stride=(1, 16, 16))
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (head_drop): Identity()
  (head): Linear(in_features=576, out_features=28, bias=True)
  (drop_path): DropPath()
  (layers): ModuleList(
    (0-1): 2 x Block(
      (mixer): Mamba(
        (in_proj): Linear(in_features=576, out_features=2304, bias=False)
        (conv1d): Conv1d(1152, 1152, kernel_size=(4,), stride=(1,), padding=(3,), groups=1152)
        (act): SiLU()
        (x_proj): Linear(in_features=1152, out_features=68, bias=False)
        (dt_proj): Linear(in_features=36, out_features=1152, bias=True)
        (conv1d_b): Conv1d(1152, 1152, kernel_size=(4,), stride=(1,), padding=(3,), groups=1152)
        (x_proj_b): Linear(in_features=1152, out_features=68, bias=False)
        (dt_proj_b): Linear(in_features=36, out_features=1152, bias=True)
        (out_proj): Linear(in_features=1152, out_features=576, bias=False)
      )
      (norm): RMSNorm()
      (drop_path): Identity()
    )
    (2-31): 30 x Block(
      (mixer): Mamba(
        (in_proj): Linear(in_features=576, out_features=2304, bias=False)
        (conv1d): Conv1d(1152, 1152, kernel_size=(4,), stride=(1,), padding=(3,), groups=1152)
        (act): SiLU()
        (x_proj): Linear(in_features=1152, out_features=68, bias=False)
        (dt_proj): Linear(in_features=36, out_features=1152, bias=True)
        (conv1d_b): Conv1d(1152, 1152, kernel_size=(4,), stride=(1,), padding=(3,), groups=1152)
        (x_proj_b): Linear(in_features=1152, out_features=68, bias=False)
        (dt_proj_b): Linear(in_features=36, out_features=1152, bias=True)
        (out_proj): Linear(in_features=1152, out_features=576, bias=False)
      )
      (norm): RMSNorm()
      (drop_path): DropPath()
    )
  )
  (norm_f): RMSNorm()
)
number of params: 73675036
LR = 0.00050000
Batch size = 128
Repeated sample = 1
Update frequent = 1
Number of training examples = 3191
Number of training training per epoch = 24
Assigned values = [0.0006338253001141158, 0.0007922816251426448, 0.0009903520314283058, 0.0012379400392853823, 0.0015474250491067279, 0.0019342813113834097, 0.002417851639229262, 0.0030223145490365774, 0.0037778931862957215, 0.004722366482869652, 0.005902958103587064, 0.00737869762948383, 0.009223372036854787, 0.011529215046068483, 0.014411518807585602, 0.018014398509482003, 0.022517998136852502, 0.028147497671065624, 0.03518437208883203, 0.043980465111040035, 0.054975581388800036, 0.06871947673600004, 0.08589934592000005, 0.10737418240000006, 0.13421772800000006, 0.1677721600000001, 0.20971520000000007, 0.2621440000000001, 0.3276800000000001, 0.4096000000000001, 0.5120000000000001, 0.6400000000000001, 0.8, 1.0]
Skip weight decay list:  {'pos_embed', 'temporal_pos_embedding', 'cls_token'}
Param groups = {
  "layer_0_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "cls_token",
      "pos_embed",
      "patch_embed.proj.bias"
    ],
    "lr_scale": 0.0006338253001141158
  },
  "layer_33_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "temporal_pos_embedding",
      "head.bias",
      "layers.0.mixer.D",
      "layers.0.mixer.D_b",
      "layers.0.mixer.conv1d.bias",
      "layers.0.mixer.dt_proj.bias",
      "layers.0.mixer.conv1d_b.bias",
      "layers.0.mixer.dt_proj_b.bias",
      "layers.0.norm.weight",
      "layers.1.mixer.D",
      "layers.1.mixer.D_b",
      "layers.1.mixer.conv1d.bias",
      "layers.1.mixer.dt_proj.bias",
      "layers.1.mixer.conv1d_b.bias",
      "layers.1.mixer.dt_proj_b.bias",
      "layers.1.norm.weight",
      "layers.2.mixer.D",
      "layers.2.mixer.D_b",
      "layers.2.mixer.conv1d.bias",
      "layers.2.mixer.dt_proj.bias",
      "layers.2.mixer.conv1d_b.bias",
      "layers.2.mixer.dt_proj_b.bias",
      "layers.2.norm.weight",
      "layers.3.mixer.D",
      "layers.3.mixer.D_b",
      "layers.3.mixer.conv1d.bias",
      "layers.3.mixer.dt_proj.bias",
      "layers.3.mixer.conv1d_b.bias",
      "layers.3.mixer.dt_proj_b.bias",
      "layers.3.norm.weight",
      "layers.4.mixer.D",
      "layers.4.mixer.D_b",
      "layers.4.mixer.conv1d.bias",
      "layers.4.mixer.dt_proj.bias",
      "layers.4.mixer.conv1d_b.bias",
      "layers.4.mixer.dt_proj_b.bias",
      "layers.4.norm.weight",
      "layers.5.mixer.D",
      "layers.5.mixer.D_b",
      "layers.5.mixer.conv1d.bias",
      "layers.5.mixer.dt_proj.bias",
      "layers.5.mixer.conv1d_b.bias",
      "layers.5.mixer.dt_proj_b.bias",
      "layers.5.norm.weight",
      "layers.6.mixer.D",
      "layers.6.mixer.D_b",
      "layers.6.mixer.conv1d.bias",
      "layers.6.mixer.dt_proj.bias",
      "layers.6.mixer.conv1d_b.bias",
      "layers.6.mixer.dt_proj_b.bias",
      "layers.6.norm.weight",
      "layers.7.mixer.D",
      "layers.7.mixer.D_b",
      "layers.7.mixer.conv1d.bias",
      "layers.7.mixer.dt_proj.bias",
      "layers.7.mixer.conv1d_b.bias",
      "layers.7.mixer.dt_proj_b.bias",
      "layers.7.norm.weight",
      "layers.8.mixer.D",
      "layers.8.mixer.D_b",
      "layers.8.mixer.conv1d.bias",
      "layers.8.mixer.dt_proj.bias",
      "layers.8.mixer.conv1d_b.bias",
      "layers.8.mixer.dt_proj_b.bias",
      "layers.8.norm.weight",
      "layers.9.mixer.D",
      "layers.9.mixer.D_b",
      "layers.9.mixer.conv1d.bias",
      "layers.9.mixer.dt_proj.bias",
      "layers.9.mixer.conv1d_b.bias",
      "layers.9.mixer.dt_proj_b.bias",
      "layers.9.norm.weight",
      "layers.10.mixer.D",
      "layers.10.mixer.D_b",
      "layers.10.mixer.conv1d.bias",
      "layers.10.mixer.dt_proj.bias",
      "layers.10.mixer.conv1d_b.bias",
      "layers.10.mixer.dt_proj_b.bias",
      "layers.10.norm.weight",
      "layers.11.mixer.D",
      "layers.11.mixer.D_b",
      "layers.11.mixer.conv1d.bias",
      "layers.11.mixer.dt_proj.bias",
      "layers.11.mixer.conv1d_b.bias",
      "layers.11.mixer.dt_proj_b.bias",
      "layers.11.norm.weight",
      "layers.12.mixer.D",
      "layers.12.mixer.D_b",
      "layers.12.mixer.conv1d.bias",
      "layers.12.mixer.dt_proj.bias",
      "layers.12.mixer.conv1d_b.bias",
      "layers.12.mixer.dt_proj_b.bias",
      "layers.12.norm.weight",
      "layers.13.mixer.D",
      "layers.13.mixer.D_b",
      "layers.13.mixer.conv1d.bias",
      "layers.13.mixer.dt_proj.bias",
      "layers.13.mixer.conv1d_b.bias",
      "layers.13.mixer.dt_proj_b.bias",
      "layers.13.norm.weight",
      "layers.14.mixer.D",
      "layers.14.mixer.D_b",
      "layers.14.mixer.conv1d.bias",
      "layers.14.mixer.dt_proj.bias",
      "layers.14.mixer.conv1d_b.bias",
      "layers.14.mixer.dt_proj_b.bias",
      "layers.14.norm.weight",
      "layers.15.mixer.D",
      "layers.15.mixer.D_b",
      "layers.15.mixer.conv1d.bias",
      "layers.15.mixer.dt_proj.bias",
      "layers.15.mixer.conv1d_b.bias",
      "layers.15.mixer.dt_proj_b.bias",
      "layers.15.norm.weight",
      "layers.16.mixer.D",
      "layers.16.mixer.D_b",
      "layers.16.mixer.conv1d.bias",
      "layers.16.mixer.dt_proj.bias",
      "layers.16.mixer.conv1d_b.bias",
      "layers.16.mixer.dt_proj_b.bias",
      "layers.16.norm.weight",
      "layers.17.mixer.D",
      "layers.17.mixer.D_b",
      "layers.17.mixer.conv1d.bias",
      "layers.17.mixer.dt_proj.bias",
      "layers.17.mixer.conv1d_b.bias",
      "layers.17.mixer.dt_proj_b.bias",
      "layers.17.norm.weight",
      "layers.18.mixer.D",
      "layers.18.mixer.D_b",
      "layers.18.mixer.conv1d.bias",
      "layers.18.mixer.dt_proj.bias",
      "layers.18.mixer.conv1d_b.bias",
      "layers.18.mixer.dt_proj_b.bias",
      "layers.18.norm.weight",
      "layers.19.mixer.D",
      "layers.19.mixer.D_b",
      "layers.19.mixer.conv1d.bias",
      "layers.19.mixer.dt_proj.bias",
      "layers.19.mixer.conv1d_b.bias",
      "layers.19.mixer.dt_proj_b.bias",
      "layers.19.norm.weight",
      "layers.20.mixer.D",
      "layers.20.mixer.D_b",
      "layers.20.mixer.conv1d.bias",
      "layers.20.mixer.dt_proj.bias",
      "layers.20.mixer.conv1d_b.bias",
      "layers.20.mixer.dt_proj_b.bias",
      "layers.20.norm.weight",
      "layers.21.mixer.D",
      "layers.21.mixer.D_b",
      "layers.21.mixer.conv1d.bias",
      "layers.21.mixer.dt_proj.bias",
      "layers.21.mixer.conv1d_b.bias",
      "layers.21.mixer.dt_proj_b.bias",
      "layers.21.norm.weight",
      "layers.22.mixer.D",
      "layers.22.mixer.D_b",
      "layers.22.mixer.conv1d.bias",
      "layers.22.mixer.dt_proj.bias",
      "layers.22.mixer.conv1d_b.bias",
      "layers.22.mixer.dt_proj_b.bias",
      "layers.22.norm.weight",
      "layers.23.mixer.D",
      "layers.23.mixer.D_b",
      "layers.23.mixer.conv1d.bias",
      "layers.23.mixer.dt_proj.bias",
      "layers.23.mixer.conv1d_b.bias",
      "layers.23.mixer.dt_proj_b.bias",
      "layers.23.norm.weight",
      "layers.24.mixer.D",
      "layers.24.mixer.D_b",
      "layers.24.mixer.conv1d.bias",
      "layers.24.mixer.dt_proj.bias",
      "layers.24.mixer.conv1d_b.bias",
      "layers.24.mixer.dt_proj_b.bias",
      "layers.24.norm.weight",
      "layers.25.mixer.D",
      "layers.25.mixer.D_b",
      "layers.25.mixer.conv1d.bias",
      "layers.25.mixer.dt_proj.bias",
      "layers.25.mixer.conv1d_b.bias",
      "layers.25.mixer.dt_proj_b.bias",
      "layers.25.norm.weight",
      "layers.26.mixer.D",
      "layers.26.mixer.D_b",
      "layers.26.mixer.conv1d.bias",
      "layers.26.mixer.dt_proj.bias",
      "layers.26.mixer.conv1d_b.bias",
      "layers.26.mixer.dt_proj_b.bias",
      "layers.26.norm.weight",
      "layers.27.mixer.D",
      "layers.27.mixer.D_b",
      "layers.27.mixer.conv1d.bias",
      "layers.27.mixer.dt_proj.bias",
      "layers.27.mixer.conv1d_b.bias",
      "layers.27.mixer.dt_proj_b.bias",
      "layers.27.norm.weight",
      "layers.28.mixer.D",
      "layers.28.mixer.D_b",
      "layers.28.mixer.conv1d.bias",
      "layers.28.mixer.dt_proj.bias",
      "layers.28.mixer.conv1d_b.bias",
      "layers.28.mixer.dt_proj_b.bias",
      "layers.28.norm.weight",
      "layers.29.mixer.D",
      "layers.29.mixer.D_b",
      "layers.29.mixer.conv1d.bias",
      "layers.29.mixer.dt_proj.bias",
      "layers.29.mixer.conv1d_b.bias",
      "layers.29.mixer.dt_proj_b.bias",
      "layers.29.norm.weight",
      "layers.30.mixer.D",
      "layers.30.mixer.D_b",
      "layers.30.mixer.conv1d.bias",
      "layers.30.mixer.dt_proj.bias",
      "layers.30.mixer.conv1d_b.bias",
      "layers.30.mixer.dt_proj_b.bias",
      "layers.30.norm.weight",
      "layers.31.mixer.D",
      "layers.31.mixer.D_b",
      "layers.31.mixer.conv1d.bias",
      "layers.31.mixer.dt_proj.bias",
      "layers.31.mixer.conv1d_b.bias",
      "layers.31.mixer.dt_proj_b.bias",
      "layers.31.norm.weight",
      "norm_f.weight"
    ],
    "lr_scale": 1.0
  },
  "layer_0_decay": {
    "weight_decay": 0.05,
    "params": [
      "patch_embed.proj.weight"
    ],
    "lr_scale": 0.0006338253001141158
  },
  "layer_33_decay": {
    "weight_decay": 0.05,
    "params": [
      "head.weight",
      "layers.0.mixer.A_log",
      "layers.0.mixer.A_b_log",
      "layers.0.mixer.in_proj.weight",
      "layers.0.mixer.conv1d.weight",
      "layers.0.mixer.x_proj.weight",
      "layers.0.mixer.dt_proj.weight",
      "layers.0.mixer.conv1d_b.weight",
      "layers.0.mixer.x_proj_b.weight",
      "layers.0.mixer.dt_proj_b.weight",
      "layers.0.mixer.out_proj.weight",
      "layers.1.mixer.A_log",
      "layers.1.mixer.A_b_log",
      "layers.1.mixer.in_proj.weight",
      "layers.1.mixer.conv1d.weight",
      "layers.1.mixer.x_proj.weight",
      "layers.1.mixer.dt_proj.weight",
      "layers.1.mixer.conv1d_b.weight",
      "layers.1.mixer.x_proj_b.weight",
      "layers.1.mixer.dt_proj_b.weight",
      "layers.1.mixer.out_proj.weight",
      "layers.2.mixer.A_log",
      "layers.2.mixer.A_b_log",
      "layers.2.mixer.in_proj.weight",
      "layers.2.mixer.conv1d.weight",
      "layers.2.mixer.x_proj.weight",
      "layers.2.mixer.dt_proj.weight",
      "layers.2.mixer.conv1d_b.weight",
      "layers.2.mixer.x_proj_b.weight",
      "layers.2.mixer.dt_proj_b.weight",
      "layers.2.mixer.out_proj.weight",
      "layers.3.mixer.A_log",
      "layers.3.mixer.A_b_log",
      "layers.3.mixer.in_proj.weight",
      "layers.3.mixer.conv1d.weight",
      "layers.3.mixer.x_proj.weight",
      "layers.3.mixer.dt_proj.weight",
      "layers.3.mixer.conv1d_b.weight",
      "layers.3.mixer.x_proj_b.weight",
      "layers.3.mixer.dt_proj_b.weight",
      "layers.3.mixer.out_proj.weight",
      "layers.4.mixer.A_log",
      "layers.4.mixer.A_b_log",
      "layers.4.mixer.in_proj.weight",
      "layers.4.mixer.conv1d.weight",
      "layers.4.mixer.x_proj.weight",
      "layers.4.mixer.dt_proj.weight",
      "layers.4.mixer.conv1d_b.weight",
      "layers.4.mixer.x_proj_b.weight",
      "layers.4.mixer.dt_proj_b.weight",
      "layers.4.mixer.out_proj.weight",
      "layers.5.mixer.A_log",
      "layers.5.mixer.A_b_log",
      "layers.5.mixer.in_proj.weight",
      "layers.5.mixer.conv1d.weight",
      "layers.5.mixer.x_proj.weight",
      "layers.5.mixer.dt_proj.weight",
      "layers.5.mixer.conv1d_b.weight",
      "layers.5.mixer.x_proj_b.weight",
      "layers.5.mixer.dt_proj_b.weight",
      "layers.5.mixer.out_proj.weight",
      "layers.6.mixer.A_log",
      "layers.6.mixer.A_b_log",
      "layers.6.mixer.in_proj.weight",
      "layers.6.mixer.conv1d.weight",
      "layers.6.mixer.x_proj.weight",
      "layers.6.mixer.dt_proj.weight",
      "layers.6.mixer.conv1d_b.weight",
      "layers.6.mixer.x_proj_b.weight",
      "layers.6.mixer.dt_proj_b.weight",
      "layers.6.mixer.out_proj.weight",
      "layers.7.mixer.A_log",
      "layers.7.mixer.A_b_log",
      "layers.7.mixer.in_proj.weight",
      "layers.7.mixer.conv1d.weight",
      "layers.7.mixer.x_proj.weight",
      "layers.7.mixer.dt_proj.weight",
      "layers.7.mixer.conv1d_b.weight",
      "layers.7.mixer.x_proj_b.weight",
      "layers.7.mixer.dt_proj_b.weight",
      "layers.7.mixer.out_proj.weight",
      "layers.8.mixer.A_log",
      "layers.8.mixer.A_b_log",
      "layers.8.mixer.in_proj.weight",
      "layers.8.mixer.conv1d.weight",
      "layers.8.mixer.x_proj.weight",
      "layers.8.mixer.dt_proj.weight",
      "layers.8.mixer.conv1d_b.weight",
      "layers.8.mixer.x_proj_b.weight",
      "layers.8.mixer.dt_proj_b.weight",
      "layers.8.mixer.out_proj.weight",
      "layers.9.mixer.A_log",
      "layers.9.mixer.A_b_log",
      "layers.9.mixer.in_proj.weight",
      "layers.9.mixer.conv1d.weight",
      "layers.9.mixer.x_proj.weight",
      "layers.9.mixer.dt_proj.weight",
      "layers.9.mixer.conv1d_b.weight",
      "layers.9.mixer.x_proj_b.weight",
      "layers.9.mixer.dt_proj_b.weight",
      "layers.9.mixer.out_proj.weight",
      "layers.10.mixer.A_log",
      "layers.10.mixer.A_b_log",
      "layers.10.mixer.in_proj.weight",
      "layers.10.mixer.conv1d.weight",
      "layers.10.mixer.x_proj.weight",
      "layers.10.mixer.dt_proj.weight",
      "layers.10.mixer.conv1d_b.weight",
      "layers.10.mixer.x_proj_b.weight",
      "layers.10.mixer.dt_proj_b.weight",
      "layers.10.mixer.out_proj.weight",
      "layers.11.mixer.A_log",
      "layers.11.mixer.A_b_log",
      "layers.11.mixer.in_proj.weight",
      "layers.11.mixer.conv1d.weight",
      "layers.11.mixer.x_proj.weight",
      "layers.11.mixer.dt_proj.weight",
      "layers.11.mixer.conv1d_b.weight",
      "layers.11.mixer.x_proj_b.weight",
      "layers.11.mixer.dt_proj_b.weight",
      "layers.11.mixer.out_proj.weight",
      "layers.12.mixer.A_log",
      "layers.12.mixer.A_b_log",
      "layers.12.mixer.in_proj.weight",
      "layers.12.mixer.conv1d.weight",
      "layers.12.mixer.x_proj.weight",
      "layers.12.mixer.dt_proj.weight",
      "layers.12.mixer.conv1d_b.weight",
      "layers.12.mixer.x_proj_b.weight",
      "layers.12.mixer.dt_proj_b.weight",
      "layers.12.mixer.out_proj.weight",
      "layers.13.mixer.A_log",
      "layers.13.mixer.A_b_log",
      "layers.13.mixer.in_proj.weight",
      "layers.13.mixer.conv1d.weight",
      "layers.13.mixer.x_proj.weight",
      "layers.13.mixer.dt_proj.weight",
      "layers.13.mixer.conv1d_b.weight",
      "layers.13.mixer.x_proj_b.weight",
      "layers.13.mixer.dt_proj_b.weight",
      "layers.13.mixer.out_proj.weight",
      "layers.14.mixer.A_log",
      "layers.14.mixer.A_b_log",
      "layers.14.mixer.in_proj.weight",
      "layers.14.mixer.conv1d.weight",
      "layers.14.mixer.x_proj.weight",
      "layers.14.mixer.dt_proj.weight",
      "layers.14.mixer.conv1d_b.weight",
      "layers.14.mixer.x_proj_b.weight",
      "layers.14.mixer.dt_proj_b.weight",
      "layers.14.mixer.out_proj.weight",
      "layers.15.mixer.A_log",
      "layers.15.mixer.A_b_log",
      "layers.15.mixer.in_proj.weight",
      "layers.15.mixer.conv1d.weight",
      "layers.15.mixer.x_proj.weight",
      "layers.15.mixer.dt_proj.weight",
      "layers.15.mixer.conv1d_b.weight",
      "layers.15.mixer.x_proj_b.weight",
      "layers.15.mixer.dt_proj_b.weight",
      "layers.15.mixer.out_proj.weight",
      "layers.16.mixer.A_log",
      "layers.16.mixer.A_b_log",
      "layers.16.mixer.in_proj.weight",
      "layers.16.mixer.conv1d.weight",
      "layers.16.mixer.x_proj.weight",
      "layers.16.mixer.dt_proj.weight",
      "layers.16.mixer.conv1d_b.weight",
      "layers.16.mixer.x_proj_b.weight",
      "layers.16.mixer.dt_proj_b.weight",
      "layers.16.mixer.out_proj.weight",
      "layers.17.mixer.A_log",
      "layers.17.mixer.A_b_log",
      "layers.17.mixer.in_proj.weight",
      "layers.17.mixer.conv1d.weight",
      "layers.17.mixer.x_proj.weight",
      "layers.17.mixer.dt_proj.weight",
      "layers.17.mixer.conv1d_b.weight",
      "layers.17.mixer.x_proj_b.weight",
      "layers.17.mixer.dt_proj_b.weight",
      "layers.17.mixer.out_proj.weight",
      "layers.18.mixer.A_log",
      "layers.18.mixer.A_b_log",
      "layers.18.mixer.in_proj.weight",
      "layers.18.mixer.conv1d.weight",
      "layers.18.mixer.x_proj.weight",
      "layers.18.mixer.dt_proj.weight",
      "layers.18.mixer.conv1d_b.weight",
      "layers.18.mixer.x_proj_b.weight",
      "layers.18.mixer.dt_proj_b.weight",
      "layers.18.mixer.out_proj.weight",
      "layers.19.mixer.A_log",
      "layers.19.mixer.A_b_log",
      "layers.19.mixer.in_proj.weight",
      "layers.19.mixer.conv1d.weight",
      "layers.19.mixer.x_proj.weight",
      "layers.19.mixer.dt_proj.weight",
      "layers.19.mixer.conv1d_b.weight",
      "layers.19.mixer.x_proj_b.weight",
      "layers.19.mixer.dt_proj_b.weight",
      "layers.19.mixer.out_proj.weight",
      "layers.20.mixer.A_log",
      "layers.20.mixer.A_b_log",
      "layers.20.mixer.in_proj.weight",
      "layers.20.mixer.conv1d.weight",
      "layers.20.mixer.x_proj.weight",
      "layers.20.mixer.dt_proj.weight",
      "layers.20.mixer.conv1d_b.weight",
      "layers.20.mixer.x_proj_b.weight",
      "layers.20.mixer.dt_proj_b.weight",
      "layers.20.mixer.out_proj.weight",
      "layers.21.mixer.A_log",
      "layers.21.mixer.A_b_log",
      "layers.21.mixer.in_proj.weight",
      "layers.21.mixer.conv1d.weight",
      "layers.21.mixer.x_proj.weight",
      "layers.21.mixer.dt_proj.weight",
      "layers.21.mixer.conv1d_b.weight",
      "layers.21.mixer.x_proj_b.weight",
      "layers.21.mixer.dt_proj_b.weight",
      "layers.21.mixer.out_proj.weight",
      "layers.22.mixer.A_log",
      "layers.22.mixer.A_b_log",
      "layers.22.mixer.in_proj.weight",
      "layers.22.mixer.conv1d.weight",
      "layers.22.mixer.x_proj.weight",
      "layers.22.mixer.dt_proj.weight",
      "layers.22.mixer.conv1d_b.weight",
      "layers.22.mixer.x_proj_b.weight",
      "layers.22.mixer.dt_proj_b.weight",
      "layers.22.mixer.out_proj.weight",
      "layers.23.mixer.A_log",
      "layers.23.mixer.A_b_log",
      "layers.23.mixer.in_proj.weight",
      "layers.23.mixer.conv1d.weight",
      "layers.23.mixer.x_proj.weight",
      "layers.23.mixer.dt_proj.weight",
      "layers.23.mixer.conv1d_b.weight",
      "layers.23.mixer.x_proj_b.weight",
      "layers.23.mixer.dt_proj_b.weight",
      "layers.23.mixer.out_proj.weight",
      "layers.24.mixer.A_log",
      "layers.24.mixer.A_b_log",
      "layers.24.mixer.in_proj.weight",
      "layers.24.mixer.conv1d.weight",
      "layers.24.mixer.x_proj.weight",
      "layers.24.mixer.dt_proj.weight",
      "layers.24.mixer.conv1d_b.weight",
      "layers.24.mixer.x_proj_b.weight",
      "layers.24.mixer.dt_proj_b.weight",
      "layers.24.mixer.out_proj.weight",
      "layers.25.mixer.A_log",
      "layers.25.mixer.A_b_log",
      "layers.25.mixer.in_proj.weight",
      "layers.25.mixer.conv1d.weight",
      "layers.25.mixer.x_proj.weight",
      "layers.25.mixer.dt_proj.weight",
      "layers.25.mixer.conv1d_b.weight",
      "layers.25.mixer.x_proj_b.weight",
      "layers.25.mixer.dt_proj_b.weight",
      "layers.25.mixer.out_proj.weight",
      "layers.26.mixer.A_log",
      "layers.26.mixer.A_b_log",
      "layers.26.mixer.in_proj.weight",
      "layers.26.mixer.conv1d.weight",
      "layers.26.mixer.x_proj.weight",
      "layers.26.mixer.dt_proj.weight",
      "layers.26.mixer.conv1d_b.weight",
      "layers.26.mixer.x_proj_b.weight",
      "layers.26.mixer.dt_proj_b.weight",
      "layers.26.mixer.out_proj.weight",
      "layers.27.mixer.A_log",
      "layers.27.mixer.A_b_log",
      "layers.27.mixer.in_proj.weight",
      "layers.27.mixer.conv1d.weight",
      "layers.27.mixer.x_proj.weight",
      "layers.27.mixer.dt_proj.weight",
      "layers.27.mixer.conv1d_b.weight",
      "layers.27.mixer.x_proj_b.weight",
      "layers.27.mixer.dt_proj_b.weight",
      "layers.27.mixer.out_proj.weight",
      "layers.28.mixer.A_log",
      "layers.28.mixer.A_b_log",
      "layers.28.mixer.in_proj.weight",
      "layers.28.mixer.conv1d.weight",
      "layers.28.mixer.x_proj.weight",
      "layers.28.mixer.dt_proj.weight",
      "layers.28.mixer.conv1d_b.weight",
      "layers.28.mixer.x_proj_b.weight",
      "layers.28.mixer.dt_proj_b.weight",
      "layers.28.mixer.out_proj.weight",
      "layers.29.mixer.A_log",
      "layers.29.mixer.A_b_log",
      "layers.29.mixer.in_proj.weight",
      "layers.29.mixer.conv1d.weight",
      "layers.29.mixer.x_proj.weight",
      "layers.29.mixer.dt_proj.weight",
      "layers.29.mixer.conv1d_b.weight",
      "layers.29.mixer.x_proj_b.weight",
      "layers.29.mixer.dt_proj_b.weight",
      "layers.29.mixer.out_proj.weight",
      "layers.30.mixer.A_log",
      "layers.30.mixer.A_b_log",
      "layers.30.mixer.in_proj.weight",
      "layers.30.mixer.conv1d.weight",
      "layers.30.mixer.x_proj.weight",
      "layers.30.mixer.dt_proj.weight",
      "layers.30.mixer.conv1d_b.weight",
      "layers.30.mixer.x_proj_b.weight",
      "layers.30.mixer.dt_proj_b.weight",
      "layers.30.mixer.out_proj.weight",
      "layers.31.mixer.A_log",
      "layers.31.mixer.A_b_log",
      "layers.31.mixer.in_proj.weight",
      "layers.31.mixer.conv1d.weight",
      "layers.31.mixer.x_proj.weight",
      "layers.31.mixer.dt_proj.weight",
      "layers.31.mixer.conv1d_b.weight",
      "layers.31.mixer.x_proj_b.weight",
      "layers.31.mixer.dt_proj_b.weight",
      "layers.31.mixer.out_proj.weight"
    ],
    "lr_scale": 1.0
  }
}
optimizer settings: {'lr': 0.0005, 'weight_decay': 0.0, 'eps': 1e-08, 'betas': [0.9, 0.999]}
Use bf16: False
Use step level LR scheduler!
Set warmup steps = 120
Set warmup steps = 0
here 24 80 0.05 0.05
Max WD = 0.0500000, Min WD = 0.0500000
criterion = SoftTargetCrossEntropy()
Auto resume checkpoint: exp_7/videomamba_middle_mask_f322_skip4_res224/checkpoint-best.pth
Resume checkpoint exp_7/videomamba_middle_mask_f322_skip4_res224/checkpoint-best.pth
With optim & sched!
